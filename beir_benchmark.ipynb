{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e067cfbd36d29",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# BEIR Benchmark Evaluation\n",
    "\n",
    "This notebook evaluate a BEIR benchmark dataset using a SentenceBERT model for dense retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bc7ee2d130fab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246dd22fe357d9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import Libraries\n",
    "\n",
    "Import the necessary libraries for data loading, model creation, retrieval, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:34:56.450288Z",
     "start_time": "2025-07-02T16:34:47.921413Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\OneDrive\\Desktop\\projects\\rag-system-evaluation\\.venv\\Lib\\site-packages\\beir\\datasets\\data_loader.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ruben\\OneDrive\\Desktop\\projects\\rag-system-evaluation\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.models import SentenceBERT\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as dres\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "import json\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e4b2ba2c62f2e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load Configuration\n",
    "\n",
    "Loads the configuration file that contains the dataset name, model name, and other parameters for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd100919068fbec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config_file = \"configs/beir_benchmark_config.json\"\n",
    "\n",
    "with open(config_file, \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906527752bc9743",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa083b03f4fd13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load Dataset\n",
    "\n",
    "Loads a specified BEIR dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a1ddd1cf00be7f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb90db2f0b542efbd40f1fbd1561790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = config['dataset']\n",
    "data_path = config['datasets_folder']\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=os.path.join(data_path, dataset)).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dec8cc63fe2c6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create the Embedding Model\n",
    "\n",
    "Creates a SentenceBERT model for dense retrieval using the specified model name from the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e5b79b797616ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = config['model_name']\n",
    "sbert = SentenceBERT(model_name)\n",
    "retriever = EvaluateRetrieval(dres(sbert, batch_size=config['batch_size']), score_function=config['score_function'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9b1d3ec458c16",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Retrieve Documents\n",
    "\n",
    "This section retrieves documents for the queries in the dataset and evaluates the retrieval performance using specified metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9883cda7870497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:35:25.829511Z",
     "start_time": "2025-07-02T16:35:01.386890Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f367787bb74000a202ab64f3969feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212381e827d44d85838695dd223223ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrieved = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63251b7049a86b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Validate the Retrieval\n",
    "\n",
    "Validates the retrieval results by checking if the retrieved documents match the expected query relevance judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f992d819090f7a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_values = config['k_values']\n",
    "results = retriever.evaluate(qrels, retrieved, k_values=k_values)\n",
    "output_folder = config[\"output_folder\"]\n",
    "run_name = f\"run_beir_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}\"\n",
    "out_path = os.path.join(output_folder, run_name)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df[\"k\"] = k_values\n",
    "\n",
    "for r in results:\n",
    "    metric = next(iter(r.keys()))\n",
    "    metric = metric.split(\"@\")[0]\n",
    "\n",
    "    values = r.values()\n",
    "\n",
    "    results_df[metric] = values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c96b322252a1f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save Results\n",
    "\n",
    "Saves the evaluation results to a CSV file and the configuration used for the evaluation to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b009a148f1be49",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(out_path, f\"results.csv\")\n",
    "results_df.to_csv(file_path, index=False)\n",
    "\n",
    "with open(os.path.join(out_path, \"used_config.json\"), \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
