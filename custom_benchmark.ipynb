{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG Benchmark Evaluation on Natural Questions\n",
    "\n",
    "This notebook evaluates a RAG (Retrieval-Augmented Generation) system on the Natural Questions dataset."
   ],
   "id": "57f51bb443694561"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup and Initialization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea118ea9e434089f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports and dependencies\n",
    "\n",
    "Import all necessary libraries for dataset loading, embeddings, LLM, text processing, and evaluation metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60407f4d1af3bd96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:19.731615Z",
     "start_time": "2025-06-23T10:38:02.338982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import evaluate\n",
    "\n",
    "from datetime import datetime\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.document import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv"
   ],
   "id": "ea4eea478c45fbb0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Config File\n",
    "\n",
    "Configure the dataset split, output folder, embedding model, chunk size, overlap, and LLM parameters."
   ],
   "id": "841ce3ea6db11221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:19.742089Z",
     "start_time": "2025-06-23T10:38:19.734133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_file = \"configs/custom_benchmark_config.json\"\n",
    "\n",
    "with open(config_file, \"r\") as f:\n",
    "    config = json.load(f)"
   ],
   "id": "5cf0ebd2fe01be71",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load API Key\n",
    "\n",
    "Load the Hugging Face API key from environment variables to authenticate model requests."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "872e3764aa05cf93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:19.750180Z",
     "start_time": "2025-06-23T10:38:19.744618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "HF_API_KEY = os.getenv(\"API_KEY2\")"
   ],
   "id": "90e3df368ffe7436",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset\n",
    "\n",
    "Load the Natural Questions dataset subset for benchmarking."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70d918d513f3e953"
  },
  {
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:28.790963Z",
     "start_time": "2025-06-23T10:38:19.752190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"natural_questions\", split=config[\"dataset_split\"])"
   ],
   "id": "292d18be6927d28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/287 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49c0b2846593478c84e46716535496b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/287 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa025f9e15b64f57be86feb2e7e498dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Initialization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae8a0c45ab8fd77c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Embeddings initialization\n",
    "\n",
    "Create the embedding model for converting text chunks into vector representations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ec0c6bbede92a4"
  },
  {
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:32.718734Z",
     "start_time": "2025-06-23T10:38:28.793977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=config[\"embedding_model_name\"]\n",
    ")"
   ],
   "id": "733553b79138a2ce",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text splitter configuration\n",
    "\n",
    "Define how the document is split into overlapping chunks for embedding and retrieval."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8989ddb91f0dfa0"
  },
  {
   "cell_type": "code",
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config[\"chunk_size\"],\n",
    "    chunk_overlap=config[\"chunk_overlap\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:32.725025Z",
     "start_time": "2025-06-23T10:38:32.720301Z"
    }
   },
   "id": "c4ec7696c36ded36",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LLM setup\n",
    "\n",
    "Configure the language model endpoint on Hugging Face Hub for text generation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f75658f377b18de7"
  },
  {
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:32.971898Z",
     "start_time": "2025-06-23T10:38:32.727492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=config[\"llm_model\"],\n",
    "    huggingfacehub_api_token=HF_API_KEY,\n",
    "    task=\"text-generation\",\n",
    "    temperature=config[\"temperature\"],\n",
    "    max_new_tokens=config[\"max_new_tokens\"],\n",
    ")\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ],
   "id": "604630da582b0af3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieval and querying\n",
    "\n",
    "Functions to retrieve relevant documents locally and query the LLM with that context."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9983a91bdc30f78"
  },
  {
   "cell_type": "code",
   "source": [
    "def retrieve_local(query, vectorstore, k=config[\"top_k\"]):\n",
    "    docs_faiss = vectorstore.similarity_search(query, k=k)\n",
    "    return [d.page_content for d in docs_faiss]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:32.980148Z",
     "start_time": "2025-06-23T10:38:32.974103Z"
    }
   },
   "id": "20b6e3f8315f79b6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def ask(query, context):\n",
    "    messages = [\n",
    "        SystemMessage(content=f\"Just answer queries based on {context}.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Answer the query: {query} based uniquely on the context: {context}, don't make up anything, just say what the context contains. If the information is not in the context, you must say you don't know. You must answer only the specified question and nothing else.\n",
    "        \"\"\")\n",
    "    ]\n",
    "    response = chat_model.invoke(messages)\n",
    "    return response.content"
   ],
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:32.986969Z",
     "start_time": "2025-06-23T10:38:32.982160Z"
    }
   },
   "id": "80d2661109411a70",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data extraction and preprocessing\n",
    "\n",
    "Functions to extract valid answers from dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d9216a27f27bb44"
  },
  {
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:33.001286Z",
     "start_time": "2025-06-23T10:38:32.990819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_answers(sample):\n",
    "    tokens = sample[\"document\"][\"tokens\"]\n",
    "    short_answer = \"\"\n",
    "    start = sample[\"annotations\"][\"short_answers\"][0][\"start_token\"]\n",
    "    end = sample[\"annotations\"][\"short_answers\"][0][\"end_token\"]\n",
    "    if len(start) > 0:\n",
    "        short_answer = \" \".join([\n",
    "            t for t, html in zip(tokens[\"token\"][int(start[0]):int(end[0])], tokens[\"is_html\"][start[0]:end[0]]) if not html\n",
    "        ])\n",
    "\n",
    "    long_answer = \"\"\n",
    "    if sample[\"annotations\"][\"long_answer\"][0][\"start_token\"] != -1:\n",
    "        start = sample[\"annotations\"][\"long_answer\"][0][\"start_token\"]\n",
    "        end = sample[\"annotations\"][\"long_answer\"][0][\"end_token\"]\n",
    "        long_answer = \" \".join([\n",
    "            t for t, html in zip(tokens[\"token\"][start:end], tokens[\"is_html\"][start:end]) if not html\n",
    "        ])\n",
    "\n",
    "    return long_answer or \"\", short_answer or \"\""
   ],
   "id": "1dd55c4e0a2d91e1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_text(sample):\n",
    "    tokens = sample[\"document\"][\"tokens\"]\n",
    "    return \" \".join([t for t, html in zip(tokens[\"token\"], tokens[\"is_html\"]) if not html])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:33.010934Z",
     "start_time": "2025-06-23T10:38:33.003416Z"
    }
   },
   "id": "b2fa481a60693a36",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmarking "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b739fec4387fcc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve benchmark\n",
    "\n",
    "By finding the longest match between the prediction and the golden context, we can evaluate how well the model retrieves relevant information."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5901ab8d628195c"
  },
  {
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:33.022402Z",
     "start_time": "2025-06-23T10:38:33.014476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_longest_match(str1, str2):\n",
    "    max_len = 0\n",
    "    len2 = len(str2)\n",
    "\n",
    "    for i in range(len2):\n",
    "        for j in range(i + 1, len2 + 1):\n",
    "            substr = str2[i:j]\n",
    "            if substr in str1 and len(substr) > max_len:\n",
    "                max_len = len(substr)\n",
    "\n",
    "    return max_len / len2 if len2 > 0 else 0\n"
   ],
   "id": "5b2c257fcdb1d26b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation benchmark\n",
    "\n",
    "Load rouge and bleu metrics for evaluating the model's predictions against the golden answers. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b5dc984b0153086"
  },
  {
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:36.401793Z",
     "start_time": "2025-06-23T10:38:33.025949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metric_rouge = evaluate.load(\"rouge\")\n",
    "metric_bleu = evaluate.load(\"bleu\")"
   ],
   "id": "b76c5209da15957e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Single sample processing\n",
    "\n",
    "Process one sample: build context, eventually query LLM, extract answer, and compute metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d72a8cb8659c09c9"
  },
  {
   "cell_type": "code",
   "source": [
    "def process_sample(i, sample, use_llm):\n",
    "    golden_context, golden_answer = extract_answers(sample)\n",
    "    if golden_answer == \"\" or golden_context == \"\":\n",
    "        return None\n",
    "    \n",
    "    query = sample[\"question\"][\"text\"]\n",
    "    \n",
    "    # Standard request\n",
    "    text = preprocess_text(sample)\n",
    "    docs = [Document(page_content=text)]\n",
    "    split_docs = splitter.split_documents(docs)\n",
    "    vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
    "    context = retrieve_local(query, vectorstore)\n",
    "    \n",
    "    if use_llm:\n",
    "        prediction = ask(query, context)\n",
    "    else:   \n",
    "        prediction = context[0]\n",
    "        \n",
    "    rouge = metric_rouge.compute(predictions=[prediction], references=[golden_context])\n",
    "    bleu = metric_bleu.compute(predictions=[prediction], references=[golden_context])\n",
    "    longest_match = find_longest_match(prediction, golden_context)\n",
    "    \n",
    "    # Golden answer scenario\n",
    "    if use_llm:\n",
    "        prediction_golden = ask(query, golden_context)\n",
    "    else:\n",
    "        prediction_golden = golden_context\n",
    "        \n",
    "    rouge_golden = metric_rouge.compute(predictions=[prediction_golden], references=[golden_context])\n",
    "    bleu_golden = metric_bleu.compute(predictions=[prediction_golden], references=[golden_context])\n",
    "    longest_match_golden = find_longest_match(prediction_golden, golden_context)\n",
    "\n",
    "    result = {\n",
    "        \"index\": i,\n",
    "        \"rougeL\": rouge[\"rougeL\"],\n",
    "        \"rougeL_golden\": rouge_golden[\"rougeL\"],\n",
    "        \"bleu\": bleu[\"bleu\"],\n",
    "        \"bleu_golden\": bleu_golden[\"bleu\"],\n",
    "        \"longest_match\": longest_match,\n",
    "        \"longest_match_golden\": longest_match_golden,\n",
    "        \"query\": query,\n",
    "        \"gold_answer\": golden_answer,\n",
    "        \"prediction\": prediction,\n",
    "        \"prediction_golden\": prediction_golden,\n",
    "    }\n",
    "    result.update({k: str(v) for k, v in config.items()})  # Add config values\n",
    "    return result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:38:36.415411Z",
     "start_time": "2025-06-23T10:38:36.405318Z"
    }
   },
   "id": "91dd8c46c6a1cb9e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Full benchmark loop\n",
    "\n",
    "Run the evaluation until the target number of valid samples with answers is reached, skipping samples with empty references."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3b8db3a1ad908b0"
  },
  {
   "cell_type": "code",
   "source": [
    "num_valid_examples = config[\"num_valid_examples\"]\n",
    "use_llm = config[\"use_llm\"]\n",
    "\n",
    "results = []\n",
    "i = 0\n",
    "\n",
    "with tqdm(total=num_valid_examples) as pbar:\n",
    "    while len(results) < num_valid_examples and i < len(dataset):\n",
    "        sample = dataset[i]\n",
    "        \n",
    "        result = process_sample(i, sample, use_llm)\n",
    "            \n",
    "        if result:\n",
    "            results.append(result)\n",
    "            pbar.update(1)\n",
    "            \n",
    "        i += 1\n",
    "\n",
    "print(f\"Processed {len(results)} valid samples out of {i} total samples\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:39:13.731763Z",
     "start_time": "2025-06-23T10:38:36.416940Z"
    }
   },
   "id": "c273ca2913c053a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 valid samples out of 40 total samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save and display results\n",
    "\n",
    "Print average metric scores, save data to CSV and JSON."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f2581af0cde6a2c"
  },
  {
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:39:13.739931Z",
     "start_time": "2025-06-23T10:39:13.732774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for r in results:\n",
    "    print(f\"\\n\\n===================================== SAMPLE {r['index']} =====================================\")\n",
    "    print(f\"QUERY: {r['query']}\\n\")\n",
    "    print(f\"PREDICTION: {r['prediction']}\\n\")\n",
    "    print(f\"PREDICTION (GOLDEN): {r['prediction_golden']}\\n\")\n",
    "    print(f\"GOLDEN ANSWER: {r['gold_answer']}\\n\")\n",
    "    print(f\"rougeL: {r['rougeL']}, rougeL_golden: {r['rougeL_golden']}\")\n",
    "    print(f\"bleu: {r['bleu']}, blue golden: {r['bleu_golden']}\")\n",
    "    print(f\"longest match: {r['longest_match']}, longest match golden: {r['longest_match_golden']}\")"
   ],
   "id": "34638e2b890f8ac6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===================================== SAMPLE 11 =====================================\n",
      "QUERY: when did now thats what i call music come out\n",
      "\n",
      "PREDICTION: Now That 's What I Call Music ( 1983 ) Now That 's What I Call Music II ( 1984 ) Now That 's What I Call Music ( also simply titled Now or Now 1 ) is the first album from the popular Now ! series\n",
      "\n",
      "PREDICTION (GOLDEN): Now That 's What I Call Music ( also simply titled Now or Now 1 ) is the first album from the popular Now ! series that was released in the United Kingdom on 28 November 1983 . Initial pressings were released on vinyl and audio cassette . To celebrate the 25th anniversary of the album and series , the album was re-released on CD for the first time in 2009 . However , alternative longer mixes of Only For Love , Double Dutch and Candy Girl were included in place of the original shorter single mixes from 1983 . A double vinyl re-release followed for Record Store Day on 18 April 2015 . In July 2018 , the album was newly remastered and re-released on CD , vinyl and cassette to commemorate the release of the 100th volume of the series .\n",
      "\n",
      "GOLDEN ANSWER: 28 November 1983\n",
      "\n",
      "rougeL: 0.26744186046511625, rougeL_golden: 1.0\n",
      "bleu: 0.07044674197162036, blue golden: 1.0\n",
      "longest match: 0.15405405405405406, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 13 =====================================\n",
      "QUERY: where is the 2018 grey cup being played\n",
      "\n",
      "PREDICTION: : Grey Cup Grey Cups hosted in Edmonton Scheduled sports events 2018 in Canadian football 2018 in Canadian television 2010s in Edmonton 2018 in Alberta 2018 sports awards November 2018 sports events\n",
      "\n",
      "PREDICTION (GOLDEN): The game is scheduled to be played at The Brick Field at Commonwealth Stadium in Edmonton , Alberta on Sunday , November 25 , 2018 .\n",
      "\n",
      "GOLDEN ANSWER: The Brick Field at Commonwealth Stadium in Edmonton , Alberta\n",
      "\n",
      "rougeL: 0.22641509433962262, rougeL_golden: 1.0\n",
      "bleu: 0.0, blue golden: 1.0\n",
      "longest match: 0.09848484848484848, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 16 =====================================\n",
      "QUERY: where did the band bastille get their name\n",
      "\n",
      "PREDICTION: Bastille ( band ) - wikipedia Bastille ( band ) Jump to : navigation , search Bastille Bastille performing at Coachella in 2014 Background information Origin London , England , United Kingdom Genres\n",
      "\n",
      "PREDICTION (GOLDEN): Bastille ( stylised as BΔSTILLE ) are a British rock band formed in 2010 . The group began as a solo project by lead vocalist Dan Smith , but later expanded to include keyboardist Kyle Simmons , bassist and guitarist Will Farquarson , and drummer Chris Wood . The name of the band derives from Bastille Day , which is celebrated on 14 July , the date of Smith 's birthday .\n",
      "\n",
      "GOLDEN ANSWER: Bastille Day\n",
      "\n",
      "rougeL: 0.09195402298850575, rougeL_golden: 1.0\n",
      "bleu: 0.0, blue golden: 1.0\n",
      "longest match: 0.029490616621983913, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 17 =====================================\n",
      "QUERY: where is arkansas river located on a map\n",
      "\n",
      "PREDICTION: Digital Maps : Digital Collections of Oklahoma and Indian Territory `` Arkansas , a river of the United States of America '' . Encyclopædia Britannica ( 11th ed . ) . 1911 . `` Arkansas River '' .\n",
      "\n",
      "PREDICTION (GOLDEN): Arkansas River River The lower part of the Arkansas River near Little Rock , Arkansas Country United States States Colorado , Kansas , Oklahoma , Arkansas Region Great Plains Part of Mississippi River watershed Tributaries - left Fountain Creek , Pawnee River , Little Arkansas River , Walnut River , Verdigris River , Neosho River - right Cimarron River , Salt Fork Arkansas River , Canadian River , Poteau River Cities Pueblo , CO , Wichita , KS , Tulsa , OK , Muskogee , OK , Fort Smith , AR , Little Rock , AR , Pine Bluff , AR Source Confluence of East Fork Arkansas River and Tennessee Creek - location Near Leadville , Rocky Mountains , Colorado - elevation 9,728 ft ( 2,965 m ) - coordinates 39 ° 15 ′ 30 '' N 106 ° 20 ′ 38 '' W ﻿ / ﻿ 39.25833 ° N 106.34389 ° W ﻿ / 39.25833 ; - 106.34389 Mouth Mississippi River - location Franklin Township , Desha County , near Napoleon , Arkansas - elevation 108 ft ( 33 m ) - coordinates 33 ° 46 ′ 30 '' N 91 ° 04 ′ 15 '' W ﻿ / ﻿ 33.77500 ° N 91.07083 ° W ﻿ / 33.77500 ; - 91.07083 Coordinates : 33 ° 46 ′ 30 '' N 91 ° 04 ′ 15 '' W ﻿ / ﻿ 33.77500 ° N 91.07083 ° W ﻿ / 33.77500 ; - 91.07083 Length 1,469 mi ( 2,364 km ) , West - east Basin 168,002 sq mi ( 435,123 km ) Discharge for Dardanelle , Arkansas , river mile 219.5 ( river kilometer 353.3 ) - average 40,517 cu ft / s ( 1,147 m / s ) - max 683,000 cu ft / s ( 19,340 m / s ) - min 1,207 cu ft / s ( 34 m / s ) The Arkansas River flows through Colorado , Kansas , Oklahoma , and Arkansas , and its watershed also drains parts of Texas , New Mexico and Missouri .\n",
      "\n",
      "GOLDEN ANSWER: The Arkansas River flows through Colorado , Kansas , Oklahoma , and Arkansas , and its watershed also drains parts of Texas , New Mexico and Missouri .\n",
      "\n",
      "rougeL: 0.06521739130434782, rougeL_golden: 1.0\n",
      "bleu: 0.0, blue golden: 1.0\n",
      "longest match: 0.010223642172523962, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 18 =====================================\n",
      "QUERY: who plays nicholas in the princess diaries 2\n",
      "\n",
      "PREDICTION: The Princess Diaries 2 : Royal Engagement - wikipedia The Princess Diaries 2 : Royal Engagement Jump to : navigation , search The Princess Diaries 2 : Royal Engagement Theatrical release poster\n",
      "\n",
      "PREDICTION (GOLDEN): Most of the cast returned from the first film , including Julie Andrews , Anne Hathaway , Héctor Elizondo , Heather Matarazzo , and Larry Miller . Garry Marshall returned to direct and Debra Martin Chase to produce . New characters include Viscount Mabrey ( John Rhys - Davies ) , Lord Nicholas Devereaux ( Chris Pine ) , and Andrew Jacoby ( Callum Blue ) .\n",
      "\n",
      "GOLDEN ANSWER: Chris Pine\n",
      "\n",
      "rougeL: 0.07792207792207793, rougeL_golden: 1.0\n",
      "bleu: 0.0, blue golden: 1.0\n",
      "longest match: 0.011204481792717087, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 22 =====================================\n",
      "QUERY: the p-wave phase of an electrocardiogram (ecg) represents\n",
      "\n",
      "PREDICTION: P wave ( electrocardiography ) - wikipedia P wave ( electrocardiography ) Normal P wave , shown in darker red The P wave in the ECG represents atrial depolarization , which results in atrial\n",
      "\n",
      "PREDICTION (GOLDEN): The P wave in the ECG represents atrial depolarization , which results in atrial contraction , or atrial systole .\n",
      "\n",
      "GOLDEN ANSWER: atrial depolarization\n",
      "\n",
      "rougeL: 0.5909090909090909, rougeL_golden: 1.0\n",
      "bleu: 0.3899653351442684, blue golden: 1.0\n",
      "longest match: 0.7017543859649122, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 23 =====================================\n",
      "QUERY: when did star trek the next generation first air\n",
      "\n",
      "PREDICTION: conceptual work . Star Trek : The Next Generation was announced on October 10 , 1986 , and its cast in May 1987 . Paramount executive Rick Berman was assigned to the show at Roddenberry 's request .\n",
      "\n",
      "PREDICTION (GOLDEN): Season Episodes Originally aired First aired Last aired 26 September 28 , 1987 ( 1987 - 09 - 28 ) May 16 , 1988 ( 1988 - 05 - 16 ) 22 November 21 , 1988 ( 1988 - 11 - 21 ) July 17 , 1989 ( 1989 - 07 - 17 ) 26 September 25 , 1989 ( 1989 - 09 - 25 ) June 18 , 1990 ( 1990 - 06 - 18 ) 26 September 24 , 1990 ( 1990 - 09 - 24 ) June 17 , 1991 ( 1991 - 06 - 17 ) 5 26 September 23 , 1991 ( 1991 - 09 - 23 ) June 15 , 1992 ( 1992 - 06 - 15 ) 6 26 September 21 , 1992 ( 1992 - 09 - 21 ) June 21 , 1993 ( 1993 - 06 - 21 ) 7 26 September 20 , 1993 ( 1993 - 09 - 20 ) May 23 , 1994 ( 1994 - 05 - 23 )\n",
      "\n",
      "GOLDEN ANSWER: September 28 , 1987\n",
      "\n",
      "rougeL: 0.014925373134328358, rougeL_golden: 1.0\n",
      "bleu: 0.0, blue golden: 1.0\n",
      "longest match: 0.010169491525423728, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 32 =====================================\n",
      "QUERY: who sang the most wonderful summer of my life\n",
      "\n",
      "PREDICTION: an American singer , regarded as a `` one - hit wonder '' of 1963 million - selling song `` Wonderful Summer '' . However , using her real name she was highly accomplished and successful singing in\n",
      "\n",
      "PREDICTION (GOLDEN): Jackie Ward ( born Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an American singer , regarded as a `` one - hit wonder '' of 1963 million - selling song `` Wonderful Summer '' . However , using her real name she was highly accomplished and successful singing in groups . Ward 's voice is heard in U.S. television series , motion pictures , advertisements , and pop records . She is one of the real singers of the hits attributed to The Partridge Family .\n",
      "\n",
      "GOLDEN ANSWER: Jackie Ward\n",
      "\n",
      "rougeL: 0.5686274509803921, rougeL_golden: 1.0\n",
      "bleu: 0.24050846320834207, blue golden: 1.0\n",
      "longest match: 0.4164904862579281, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 37 =====================================\n",
      "QUERY: how many oscars did on golden pond win\n",
      "\n",
      "PREDICTION: for the most Oscars won by a thespian . On Golden Pond is also one of the few movies to earn the nominations for five major Academy Awards ( Best Picture , Director , Actor , Actress , and Screenplay\n",
      "\n",
      "PREDICTION (GOLDEN): The film received ten nominations at the 54th Academy Awards including Best Picture and won three : Best Actor ( Fonda ) , Best Actress ( Hepburn ) and Best Adapted Screenplay ( Thompson ) . Henry Fonda won his only competitive Oscar with this movie and at the age of 76 , he became the oldest winner in the aforementioned category . Katharine Hepburn won her fourth Best Actress award , extending her own record for the most Oscars won by a thespian . On Golden Pond is also one of the few movies to earn the nominations for five major Academy Awards ( Best Picture , Director , Actor , Actress , and Screenplay ) .\n",
      "\n",
      "GOLDEN ANSWER: three\n",
      "\n",
      "rougeL: 0.5151515151515151, rougeL_golden: 1.0\n",
      "bleu: 0.14227407158651353, blue golden: 1.0\n",
      "longest match: 0.32305194805194803, longest match golden: 1.0\n",
      "\n",
      "\n",
      "===================================== SAMPLE 39 =====================================\n",
      "QUERY: who won season 4 of america's got talent\n",
      "\n",
      "PREDICTION: website Preceded by Season 3 ( 2008 ) America 's Got Talent Season 4 ( 2009 ) Succeeded by Season 5 ( 2010 ) America 's Got Talent Seasons 5 6 7 8 9 10 11 12 13 Winners Bianca Ryan Terry Fator Neal\n",
      "\n",
      "PREDICTION (GOLDEN): The fourth season of America 's Got Talent , an American television reality show talent competition , premiered on the NBC network on June 23 , 2009 . Country singer Kevin Skinner was named the winner on September 16 , 2009 . This season is the first season to be broadcast in high definition .\n",
      "\n",
      "GOLDEN ANSWER: Kevin Skinner\n",
      "\n",
      "rougeL: 0.16279069767441862, rougeL_golden: 1.0\n",
      "bleu: 0.04290106993135518, blue golden: 1.0\n",
      "longest match: 0.0782312925170068, longest match golden: 1.0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "output_folder = config[\"output_folder\"]\n",
    "run_name = f\"run_custom_{datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")}\"\n",
    "out_path = os.path.join(output_folder, run_name)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.drop([\"prediction_golden\", \"prediction\"], axis=1, inplace=True)\n",
    "\n",
    "file_path = os.path.join(out_path, f\"results.csv\")\n",
    "results_df.to_csv(file_path, index=False)\n",
    "\n",
    "with open(os.path.join(out_path, \"used_config.json\"), \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T10:39:13.760102Z",
     "start_time": "2025-06-23T10:39:13.742487Z"
    }
   },
   "id": "258f9d60c1895cf1",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
